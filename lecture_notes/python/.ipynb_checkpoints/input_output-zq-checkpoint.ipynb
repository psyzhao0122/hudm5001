{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input/Output\n",
    "\n",
    "\n",
    "### Programming for Data Science\n",
    "### Last Updated: Jan 16, 2023\n",
    "---  \n",
    "\n",
    "### PREREQUISITES\n",
    "- variables\n",
    "- data types\n",
    "\n",
    "### SOURCES \n",
    "- JSON  \n",
    "https://en.wikipedia.org/wiki/JSON\n",
    "\n",
    "\n",
    "- pandas read_csv()  \n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    "\n",
    "\n",
    "- context managers  \n",
    "https://medium.com/better-programming/context-managers-in-python-go-beyond-with-open-as-file-85a27e392114\n",
    "\n",
    "\n",
    "- pickle  \n",
    "https://docs.python.org/3/library/pickle.html\n",
    "\n",
    "### OBJECTIVES\n",
    "- Introduce data formats: text, csv, json\n",
    "- Show how to work with the data formats: read, write\n",
    "- Discuss `pickle` for serializing/de-serializing objects\n",
    "- Demonstrate how to manipulate pathnames\n",
    "- Show how to test if a file exists\n",
    "- Illustrate how to list the files in a directory\n",
    "\n",
    "### CONCEPTS\n",
    "\n",
    "- text file\n",
    "- csv\n",
    "- JSON\n",
    "- `json.loads()`, `json.dump()`\n",
    "- delimiter\n",
    "- `with`, `open()`, `close()`\n",
    "- pickle and unpickle\n",
    "- using `os.path` library to manipulate directories\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON (Javastring Object Notation)\n",
    "  \n",
    "- open standard file format\n",
    "- data interchange format \n",
    "- useful human-readable format  \n",
    "- very popular \n",
    "- uses key-value pairs in a hierarchical (tree) format \n",
    "- semi-structured, flexible format\n",
    "\n",
    "**Examples**  \n",
    "One level of nesting with keys: `name_first`, `name_last`:\n",
    "\n",
    "```\n",
    "{\"name_first\":\"james\", \"name_last\":\"jordan\"}\n",
    "```\n",
    "\n",
    "\n",
    "Two levels of nesting; first holds `name`, second holds `name_first`, `name_last`:\n",
    "```\n",
    "{\"name\":{\"name_first\":\"james\", \"name_last\":\"jordan\"}}\n",
    "```\n",
    "\n",
    "or in a tree format:  \n",
    "```\n",
    "{\"name\":\n",
    "        {\n",
    "          \"name_first\":\"james\", \n",
    "          \"name_last\":\"jordan\"\n",
    "        } \n",
    "}\n",
    "```\n",
    "\n",
    "Note that python dictionaries have similar structure to JSON, as they both use key:value pairs.\n",
    "\n",
    "[Website for editing, representing JSON](http://jsoneditoronline.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON in Python\n",
    "\n",
    "built-in module `json` imported as:  \n",
    "\n",
    "```\n",
    "import json\n",
    "```\n",
    "\n",
    "**Read data in JSON format:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data:\n",
      "{\"name_first\":\"james\", \"name_last\":\"jordan\"}\n",
      "<class 'str'>\n",
      "--------------------------------------------------\n",
      "parsed python data:\n",
      "{'name_first': 'james', 'name_last': 'jordan'}\n",
      "<class 'dict'>\n",
      "james\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# open and read JSON file, containing line:\n",
    "# {\"name_first\":\"james\", \"name_last\":\"jordan\"}\n",
    "\n",
    "# NOTE: file is an arbitrary name\n",
    "with open('data_example.json', 'r') as file:\n",
    "    js = file.read()\n",
    "\n",
    "# parse json:\n",
    "di = json.loads(js)\n",
    "\n",
    "# Print Results\n",
    "print('original data:')\n",
    "print(js)\n",
    "print(type(js))\n",
    "print('-'*50)\n",
    "print('parsed python data:')\n",
    "print(di)\n",
    "print(type(di))\n",
    "print(di['name_first'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Writing data to a json file**\n",
    "\n",
    "Similar to reading JSON with `open(filename, 'r')`, the function is used in write mode `'w'`.  \n",
    "`json.dump()` writes the dict to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('filename.json', 'w') as file:\n",
    "    json.dump(di, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY FOR YOURSELF (UNGRADED EXERCISES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) JSON: Copy the above code that reads in `data_example.json`. After parsing to a dict with `json.loads(js)`, do these tasks:\n",
    "- append a new key:value pair to `di`\n",
    "- save the updated dict as a json file\n",
    "- verify the file looks correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name_first': 'james', 'name_last': 'jordan', 'new_key': 'new_val'}\n"
     ]
    }
   ],
   "source": [
    "# read the json\n",
    "with open('data_example.json', 'r') as file:\n",
    "    js = file.read()\n",
    "\n",
    "# parse json\n",
    "di = json.loads(js)\n",
    "di['new_key'] = 'new_val'\n",
    "print(di)\n",
    "\n",
    "with open('data_example_two.json', 'w') as fp:\n",
    "    json.dump(di, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text File Format \n",
    "\n",
    "- text files contain textual data (absent images)   \n",
    "- can be saved in plain text or rich text formats\n",
    "- typical extensions: txt, rtf, log, doc, docx (where doc, docx are MSFT proprietary)\n",
    "\n",
    "## Text in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in text file** using `open()`, print the data, and close the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Reuters) - President-elect Joe Biden may \n",
      "Pope Francis to have\n",
      "U.S. governors work to\n"
     ]
    }
   ],
   "source": [
    "f1 = open('data_example.txt','r') # 'r' for read mode\n",
    "data = f1.read()                  # read file content\n",
    "print(data)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `with open()` is preferred, as the file will be closed, even in the event of an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Reuters) - President-elect Joe Biden may \n",
      "Pope Francis to have\n",
      "U.S. governors work to\n",
      "\n",
      "File closed? \n",
      " True\n"
     ]
    }
   ],
   "source": [
    "with open('data_example.txt', \"r\") as f:\n",
    "    data = f.read()\n",
    "    print(data)\n",
    "\n",
    "# check if file is closed\n",
    "print('\\nFile closed? \\n', f.closed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Writing to text file**\n",
    "\n",
    "`open()` can be used again, in mode 'a' for append or 'w' for write."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append to the file\n",
    "with open('data_example.txt', \"a\") as f:\n",
    "    f.write('\\n' + 'another line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aside**  \n",
    "`with` command is called a *context manager*.   \n",
    "The context manager sets up a temporary context, and destructs the context after the operations are completed.  \n",
    "Here, it does housekeeping of opening, closing file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Format\n",
    "\n",
    "A *comma separated value* (CSV) file is a plain text file containing rows of data separated by a character, generally commas.  \n",
    "A header row containing column (field) names may be included. It's often in the first row.  \n",
    "\n",
    "Example:\n",
    "```\n",
    "name,email,phone\n",
    "laura palmer,lpalmer@twin_peaks,123-456-7890,\n",
    "agent dale cooper,dcooper@twin_peaks,123-454-7899\n",
    "```\n",
    "\n",
    "CSV format is very popular, but using comma as separator (delimiter) can be problematic:   \n",
    "if data itself contains commas, delimiter won't work properly.\n",
    "\n",
    "Popular workaround: enclose text with commas in quotes...works until data contains commas and quotes!  \n",
    "Leads to alternative delimiters such as pipe `|` which less commonly appears in data.\n",
    "#只能用PANDA，comma分割的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV in Python\n",
    "\n",
    "**Read data in csv format:**\n",
    "\n",
    "Here we use pandas `read_csv()` to read data in csv format.  \n",
    "This is the most common method for reading this format.\n",
    "\n",
    "Some important parameters:\n",
    "- *delimiter* or *sep*: the field delimiter. default is comma.\n",
    "- *header*: row number containing column names\n",
    "\n",
    "\n",
    "[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# data source: https://archive.ics.uci.edu/ml/datasets/Wine\n",
    "\n",
    "wine = pd.read_csv('data_example_wine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(wine, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_id</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflav_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>OD280_OD315</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_id  alcohol  malic_acid   ash  alcalinity  magnesium  phenols  \\\n",
       "0         1    14.23        1.71  2.43        15.6        127     2.80   \n",
       "1         1    13.20        1.78  2.14        11.2        100     2.65   \n",
       "2         1    13.16        2.36  2.67        18.6        101     2.80   \n",
       "3         1    14.37        1.95  2.50        16.8        113     3.85   \n",
       "4         1    13.24        2.59  2.87        21.0        118     2.80   \n",
       "\n",
       "   flavanoids  nonflav_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06             0.28             2.29             5.64  1.04   \n",
       "1        2.76             0.26             1.28             4.38  1.05   \n",
       "2        3.24             0.30             2.81             5.68  1.03   \n",
       "3        3.49             0.24             2.18             7.80  0.86   \n",
       "4        2.69             0.39             1.82             4.32  1.04   \n",
       "\n",
       "   OD280_OD315  proline  \n",
       "0         3.92     1065  \n",
       "1         3.40     1050  \n",
       "2         3.17     1185  \n",
       "3         3.45     1480  \n",
       "4         2.93      735  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first few rows with header\n",
    "\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data now lives in a pandas dataframe for a wide range of work.  \n",
    "We will do a lot of pandas work in the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['class_id', 'alcohol', 'malic_acid', 'ash', 'alcalinity', 'magnesium',\n",
       "       'phenols', 'flavanoids', 'nonflav_phenols', 'proanthocyanins',\n",
       "       'color_intensity', 'hue', 'OD280_OD315', 'proline'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write data to csv format:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the first two rows, saving to new csv file\n",
    "\n",
    "wine.head(2).to_csv('data_example_wine_first_two_rows.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY FOR YOURSELF (UNGRADED EXERCISES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) CSV Exercise\n",
    "\n",
    "a) Read in a dataset from this URL:  \n",
    "'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/bezdekIris.data'\n",
    "\n",
    "note: this URL can be directly passed to `read_csv()`\n",
    "\n",
    "b) You will notice the first record comes in as a header row.  \n",
    "Pass a parameter to `read_csv()` so there is no header.\n",
    "\n",
    "c) Write the data to a file with txt extension, with pipe separator |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/bezdekIris.data'\n",
    "iris = pd.read_csv(url, header=None)\n",
    "iris\n",
    "iris.to_csv('some_data.txt',sep='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pickle — Python object serialization¶\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickling converts a Python object to a byte stream (conversion to bytes is called *serialization*).  \n",
    "Unpickling is inverse operation, converting byte stream back to Python object (conversion from bytes is called *de-serialization*).\n",
    "\n",
    "The `pickle` module allows for serializing and de-serializing a Python object structure (model, dataframe, ...).  \n",
    "\n",
    "\n",
    "Some benefits:  \n",
    "- object can be compressed when pickling\n",
    "- easy to save complex data\n",
    "- easy to use (minimal code)\n",
    "\n",
    "Some differences between pickle protocols and JSON:\n",
    "\n",
    "- JSON is text serialization format, outputting unicode text; pickle is a binary serialization format\n",
    "- JSON is human-readable; pickle is not\n",
    "- JSON is interoperable and widely used outside Python; pickle is Python-specific\n",
    "\n",
    "[Details](https://docs.python.org/3/library/pickle.html)\n",
    "\n",
    "An alternative to pickle is `joblib`, which we don't discuss here.\n",
    "\n",
    "**Write to a pickle file, using context manager: `with`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "var = 5\n",
    "with open('test_pickle.pkl', 'wb') as f:\n",
    "    pickle.dump(var, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read from a pickle file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "with open('test_pickle.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pathnames & Directory Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\HUAWEI\\\\Desktop\\\\Programming_for_Data_Science\\\\repo\\\\hudm5001\\\\lecture_notes\\\\python'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions in the `os.path` module are helpful for manipulating pathnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_path = '/Users/clark_kent/data.csv'  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data.csv'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename(some_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the directory name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/clark_kent'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.dirname(some_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a path the proper way: use `os.path.join`\n",
    "\n",
    "This makes the code portable, as it adjusts for operating system.\n",
    "\n",
    "Example on a Windows machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\bruce_wayne\\\\joker.csv'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = 'C:\\\\Users\\\\bruce_wayne'\n",
    "file_name = 'joker.csv'\n",
    "\n",
    "fullpath_to_joker = os.path.join(dir_path, file_name)\n",
    "fullpath_to_joker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test if File Exists**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists('/etc/passwd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get a directory listing**\n",
    "\n",
    "Example of checking what is in the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'classes1.ipynb',\n",
       " 'classes_servers.ipynb',\n",
       " 'control_structures.ipynb',\n",
       " 'dash_basics.ipynb',\n",
       " 'dash_callback.ipynb',\n",
       " 'data_example.json',\n",
       " 'data_example.txt',\n",
       " 'data_example_two.json',\n",
       " 'data_example_wine.csv',\n",
       " 'data_example_wine_first_two_rows.csv',\n",
       " 'data_types.ipynb',\n",
       " 'data_types_zzq.ipynb',\n",
       " 'exception_handling.ipynb',\n",
       " 'filename.json',\n",
       " 'functions.ipynb',\n",
       " 'functions_calling_other_functions.ipynb',\n",
       " 'input_output-zq.ipynb',\n",
       " 'input_output.ipynb',\n",
       " 'input_output.zip',\n",
       " 'interacting_w_relational_database.py',\n",
       " 'iris_data.csv',\n",
       " 'iterables_and_iterators.ipynb',\n",
       " 'lambda_functions.ipynb',\n",
       " 'list_and_dict_comprehensions.ipynb',\n",
       " 'matplotlib.ipynb',\n",
       " 'numpy-zq.ipynb',\n",
       " 'numpy.ipynb',\n",
       " 'operators-zq.ipynb',\n",
       " 'operators.ipynb',\n",
       " 'pandas_bridges.ipynb',\n",
       " 'pandas_dataframes1.ipynb',\n",
       " 'pandas_dataframes2.ipynb',\n",
       " 'plotly.ipynb',\n",
       " 'plotnine_ggplot.ipynb',\n",
       " 'recursion.ipynb',\n",
       " 'roadmap.md',\n",
       " 'some_data.txt',\n",
       " 'sql_expl.ipynb',\n",
       " 'statsmodels.ipynb',\n",
       " 'style.css',\n",
       " 'test_pickle.pkl',\n",
       " 'unit_test_assertequal.py',\n",
       " 'unit_test_class_method_addgrade.py',\n",
       " 'unit_test_notes.md',\n",
       " 'unit_test_testsuite.py',\n",
       " 'Untitled.ipynb',\n",
       " 'variables_and_expressions.ipynb',\n",
       " 'variables_and_expressions_zzq.ipynb',\n",
       " '__name__equals__main__.ipynb']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY FOR YOURSELF (UNGRADED EXERCISES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Locate a data file on your computer and follow these steps:\n",
    "\n",
    "- create a variable containing the path to the file\n",
    "- create a variable containing the data file name\n",
    "- create a variable containing the full path (path + filename), using `os.path.join`.\n",
    "- load the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
